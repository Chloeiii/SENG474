{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Title(TBD)]\n",
    "\n",
    "Abdulla Almahmood()  \n",
    "Max Gunton()  \n",
    "Yaxi Yu(V00828218)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**1. Data Collection. (TODO)**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**2. Data Preprocessing.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing process aims to clean and transform the raw data to an useful form. In\n",
    "order to do that, we follow the next steps:  \n",
    "2.1. Deal with missing values  \n",
    "2.2. Data normalization  \n",
    "2.3. Data visualization  \n",
    "2.4. Training and Testing data set generation: To generate the files required for the\n",
    "data mining process (i.e, ARFF files for the WEKA tool)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Structured Data/epi_r.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**2.1. Deal With Missing Values.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will look at how we can identify and mark values as missing.  \n",
    "We can use plots and summary statistics to help identify missing or corrupt data.  \n",
    "We can load the dataset as a Pandas DataFrame and print summary statistics on each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             rating      calories        protein           fat        sodium  \\\n",
      "count  20052.000000  1.593500e+04   15890.000000  1.586900e+04  1.593300e+04   \n",
      "mean       3.714467  6.322958e+03     100.160793  3.468775e+02  6.225975e+03   \n",
      "std        1.340829  3.590460e+05    3840.318527  2.045611e+04  3.333182e+05   \n",
      "min        0.000000  0.000000e+00       0.000000  0.000000e+00  0.000000e+00   \n",
      "25%        3.750000  1.980000e+02       3.000000  7.000000e+00  8.000000e+01   \n",
      "50%        4.375000  3.310000e+02       8.000000  1.700000e+01  2.940000e+02   \n",
      "75%        4.375000  5.860000e+02      27.000000  3.300000e+01  7.110000e+02   \n",
      "max        5.000000  3.011122e+07  236489.000000  1.722763e+06  2.767511e+07   \n",
      "\n",
      "          #cakeweek    #wasteless  22-minute meals  3-ingredient recipes  \\\n",
      "count  20052.000000  20052.000000     20052.000000          20052.000000   \n",
      "mean       0.000299      0.000050         0.000848              0.001346   \n",
      "std        0.017296      0.007062         0.029105              0.036671   \n",
      "min        0.000000      0.000000         0.000000              0.000000   \n",
      "25%        0.000000      0.000000         0.000000              0.000000   \n",
      "50%        0.000000      0.000000         0.000000              0.000000   \n",
      "75%        0.000000      0.000000         0.000000              0.000000   \n",
      "max        1.000000      1.000000         1.000000              1.000000   \n",
      "\n",
      "       30 days of groceries      ...       yellow squash        yogurt  \\\n",
      "count          20052.000000      ...        20052.000000  20052.000000   \n",
      "mean               0.000349      ...            0.001247      0.026332   \n",
      "std                0.018681      ...            0.035288      0.160123   \n",
      "min                0.000000      ...            0.000000      0.000000   \n",
      "25%                0.000000      ...            0.000000      0.000000   \n",
      "50%                0.000000      ...            0.000000      0.000000   \n",
      "75%                0.000000      ...            0.000000      0.000000   \n",
      "max                1.000000      ...            1.000000      1.000000   \n",
      "\n",
      "            yonkers          yuca      zucchini     cookbooks     leftovers  \\\n",
      "count  20052.000000  20052.000000  20052.000000  20052.000000  20052.000000   \n",
      "mean       0.000050      0.000299      0.014861      0.000150      0.000349   \n",
      "std        0.007062      0.017296      0.121001      0.012231      0.018681   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "              snack    snack week        turkey  \n",
      "count  20052.000000  20052.000000  20052.000000  \n",
      "mean       0.001396      0.000948      0.022741  \n",
      "std        0.037343      0.030768      0.149080  \n",
      "min        0.000000      0.000000      0.000000  \n",
      "25%        0.000000      0.000000      0.000000  \n",
      "50%        0.000000      0.000000      0.000000  \n",
      "75%        0.000000      0.000000      0.000000  \n",
      "max        1.000000      1.000000      1.000000  \n",
      "\n",
      "[8 rows x 679 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we chain a .sum() method on the dataframe, we can see which column contain missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                       0\n",
       "rating                      0\n",
       "calories                 4117\n",
       "protein                  4162\n",
       "fat                      4183\n",
       "sodium                   4119\n",
       "#cakeweek                   0\n",
       "#wasteless                  0\n",
       "22-minute meals             0\n",
       "3-ingredient recipes        0\n",
       "30 days of groceries        0\n",
       "advance prep required       0\n",
       "alabama                     0\n",
       "alaska                      0\n",
       "alcoholic                   0\n",
       "almond                      0\n",
       "amaretto                    0\n",
       "anchovy                     0\n",
       "anise                       0\n",
       "anniversary                 0\n",
       "anthony bourdain            0\n",
       "aperitif                    0\n",
       "appetizer                   0\n",
       "apple                       0\n",
       "apple juice                 0\n",
       "apricot                     0\n",
       "arizona                     0\n",
       "artichoke                   0\n",
       "arugula                     0\n",
       "asian pear                  0\n",
       "                         ... \n",
       "walnut                      0\n",
       "wasabi                      0\n",
       "washington                  0\n",
       "washington, d.c.            0\n",
       "watercress                  0\n",
       "watermelon                  0\n",
       "wedding                     0\n",
       "weelicious                  0\n",
       "west virginia               0\n",
       "westwood                    0\n",
       "wheat/gluten-free           0\n",
       "whiskey                     0\n",
       "white wine                  0\n",
       "whole wheat                 0\n",
       "wild rice                   0\n",
       "windsor                     0\n",
       "wine                        0\n",
       "winter                      0\n",
       "wisconsin                   0\n",
       "wok                         0\n",
       "yellow squash               0\n",
       "yogurt                      0\n",
       "yonkers                     0\n",
       "yuca                        0\n",
       "zucchini                    0\n",
       "cookbooks                   0\n",
       "leftovers                   0\n",
       "snack                       0\n",
       "snack week                  0\n",
       "turkey                      0\n",
       "Length: 680, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list all the column names which contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calories', 'protein', 'fat', 'sodium']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest strategy for handling missing data is to remove records that contain a missing value.  \n",
    "We can do this by creating a new Pandas DataFrame with the rows containing missing values removed.  \n",
    "Pandas provides the dropna() function that can be used to drop either columns or rows with missing data. We can use dropna() to remove all rows with missing data, as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again to see if we still have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**2.2. Data normalization.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Best Blts</td>\n",
       "      <td>4.375</td>\n",
       "      <td>948.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  rating  calories  protein  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
       "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
       "5                               The Best Blts    4.375     948.0     19.0   \n",
       "\n",
       "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
       "0   7.0   559.0          0           0                0                     0   \n",
       "1  23.0  1439.0          0           0                0                     0   \n",
       "2   7.0   165.0          0           0                0                     0   \n",
       "4  32.0   452.0          0           0                0                     0   \n",
       "5  79.0  1042.0          0           0                0                     0   \n",
       "\n",
       "    ...    yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  \\\n",
       "0   ...                0       0        0     0         0          0   \n",
       "1   ...                0       0        0     0         0          0   \n",
       "2   ...                0       0        0     0         0          0   \n",
       "4   ...                0       0        0     0         0          0   \n",
       "5   ...                0       0        0     0         0          0   \n",
       "\n",
       "   leftovers  snack  snack week  turkey  \n",
       "0          0      0           0       1  \n",
       "1          0      0           0       0  \n",
       "2          0      0           0       0  \n",
       "4          0      0           0       0  \n",
       "5          0      0           0       0  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, the 1st column stores the name of each recipe;  \n",
    "the column 2 to 6 store the generational info of each recipe;  \n",
    "and the rest store the ingredients respectively (the value of these columns are eigher 0 or 1, showing whether each ingredient exist in this recipe or not).   \n",
    "\n",
    "We want to normalize the data in the 2nd to the 6th columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.375</td>\n",
       "      <td>948.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1042.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  calories  protein   fat  sodium\n",
       "0   2.500     426.0     30.0   7.0   559.0\n",
       "1   4.375     403.0     18.0  23.0  1439.0\n",
       "2   3.750     165.0      6.0   7.0   165.0\n",
       "4   3.125     547.0     20.0  32.0   452.0\n",
       "5   4.375     948.0     19.0  79.0  1042.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_general_info = data[['rating', 'calories', 'protein', 'fat', 'sodium']]\n",
    "data_general_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a method to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    return (df - df.min()) * 1.0 / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this method to normalze these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  calories   protein       fat    sodium\n",
       "0   0.500  0.000014  0.000127  0.000004  0.000020\n",
       "1   0.875  0.000013  0.000076  0.000013  0.000052\n",
       "2   0.750  0.000005  0.000025  0.000004  0.000006\n",
       "4   0.625  0.000018  0.000085  0.000019  0.000016\n",
       "5   0.875  0.000031  0.000080  0.000046  0.000038"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_general_info_normalized = data_general_info.apply(normalize)\n",
    "data_general_info_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**2.3. Data Visualization.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use seaborn to make the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.boxplot(data = data_general_info_normalized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Violin Plot to visualise the distribution of the data and its probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=data_general_info_normalized)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**2.4. Training and Testing data set generation. (TODO)**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\">**3. Data Mining.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below takes in the predictions as an array and the correct classifications and uses the two to return the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidenceInterval.py\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# TODO: expand evaluator to handle continuous class labels\n",
    "\n",
    "# class_labels must be discrete and not continuous and numerical\n",
    "\n",
    "class confidenceInterval:\n",
    "    CLT_PROB_DIST = {0.1 : 3.09,    # 99.8% confidence\n",
    "                 0.5 : 2.58,     # 99%     \"\n",
    "                 1.0 : 2.33,    # 98%      \"\n",
    "                 5.0 : 1.65,    # 90%      \"\n",
    "                 10.0 : 1.28,   # 80%      \"\n",
    "                 20.0 : 0.84,   # 60%      \"\n",
    "                 40.0 : 0.25}   # 20%      \"\n",
    "    MAX_SPREAD = 100\n",
    "    p = None\n",
    "    q = None\n",
    "    variance = None\n",
    "    SN = None\n",
    "    N = None\n",
    "    confidence = None\n",
    "    \n",
    "    \n",
    "    def __init__(self, predictions=None, class_labels=None):\n",
    "        pass\n",
    "\n",
    "    def quantizeConfidence(self, confidence):\n",
    "        index = (100 - confidence)/2.0\n",
    "        values = np.array([0.1, 0.5, 1.0, 5.0, 10.0, 20.0, 40.0])\n",
    "        diffs = abs(values - index)\n",
    "        index = values[np.argmin(diffs)]\n",
    "        return (100 - (2*index)) , index\n",
    "\n",
    "    \n",
    "    def establish(self, predictions, class_labels, confidence=90):\n",
    "        \n",
    "        assert (len(predictions) == len(class_labels))\n",
    "\n",
    "        self.confidence, index = self.quantizeConfidence(confidence)\n",
    "        self.N = len(predictions)\n",
    "\n",
    "        # ensure that the input arrays are of type numpy.array\n",
    "        predictions = np.array(predictions)     # predictions.shape = (N,)\n",
    "        class_labels = np.array(class_labels)   # class_labels.shape = (N,)\n",
    "\n",
    "        # check to make sure they are the same shape\n",
    "        assert (predictions.shape == class_labels.shape)\n",
    "\n",
    "        # compare each array element wise to see if they are the same\n",
    "        # given multiple class values if they are represented using integers\n",
    "        # the predictions can be subtracted from the actual class_labels and\n",
    "        # resulting zeros will indicate a successful predictions; anything else will\n",
    "        # indicate an error or incorrect prediction\n",
    "\n",
    "        results = class_labels - predictions\n",
    "        #print(results)  # prints correctly\n",
    "        #print(self.N)  # prints 32\n",
    "        \n",
    "        self.p = float(len([result for result in results if result == 0]))/float(self.N)\n",
    "        self.q = 1-self.p\n",
    "        self.variance = self.p*self.q/self.N\n",
    "        denom = sqrt(self.variance)\n",
    "\n",
    "        self.SN = [(self.p - self.CLT_PROB_DIST[index]*denom),\n",
    "                   (self.p + self.CLT_PROB_DIST[index]*denom)]\n",
    "\n",
    "        return\n",
    "        \n",
    "   \n",
    "    def printConfidence(self):\n",
    "        if self.SN != None:\n",
    "            # \\U+03F5 unicode for within the set\n",
    "            print('Successes: {}\\nErrors: {}\\n___________\\nTotal Instances: {}\\n\\nP: {}\\nQ: {}\\nVariance:'\n",
    "                  ' {}\\n'.format(self.p*self.N, self.q*self.N, self.N, self.p, self.q, self.variance))\n",
    "            print('With {}% confidence probability of correct classification is in the '\n",
    "                  'range {:.1f}% - {:.1f}%\\n\\n'.format(self.confidence,self.SN[0]*100,\n",
    "                                                   self.SN[1]*100))\n",
    "        else:\n",
    "            print('Confidence not yet established\\n\\n')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of a cross validator.  Will add a more in depth description about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes: 20.0\n",
      "Errors: 58.0\n",
      "___________\n",
      "Total Instances: 78\n",
      "\n",
      "P: 0.2564102564102564\n",
      "Q: 0.7435897435897436\n",
      "Variance: 0.002444410728434397\n",
      "\n",
      "With 80.0% confidence probability of correct classification is in the range 19.3% - 32.0%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# crossValidator.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold\n",
    "#from confidenceInterval import confidenceInterval\n",
    "\n",
    "# Linear Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Decision Tree Classifiers\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "CLASS_LABEL = 'rating'\n",
    "NUM_CLASSES = 6\n",
    "NUM_SPLITS = 10\n",
    "\n",
    "df = pd.read_csv('Structured Data/epi_r.csv')  # read in entire dataset\n",
    "df.fillna(-1, inplace=True)    # replace NaN values with -1\n",
    "\n",
    "# split data into attributes and class labels\n",
    "y = df[CLASS_LABEL]\n",
    "X = df[[col for col in df.columns if col != CLASS_LABEL]]\n",
    "\n",
    "# convert y to a numpy array\n",
    "y = np.array(y)\n",
    "y.reshape((-1,))\n",
    "\n",
    "# change y from being continuous values between 0-5 to simply being an integer number\n",
    "# 0, 1, 2, 3, 4, or 5\n",
    "y = pd.cut(y,NUM_CLASSES, right=False, labels=[i for i in range(NUM_CLASSES)])\n",
    "\n",
    "# print(y)\n",
    "# print(X.columns[1])\n",
    "strat_k_fold = StratifiedKFold(n_splits=NUM_SPLITS)  # parameters n_folds=10, shuffle=False, random_state=None\n",
    "\n",
    "# Here we want to cast X and y as numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# want to find the class that occurs the least often and only take that many instances\n",
    "# from each class value so that we end up with an even distribution\n",
    "minimum = np.min([len([val for val in y if val == i]) for i in range(6)])\n",
    "\n",
    "classes = np.array([],dtype=np.int32).reshape(-1,)\n",
    "for i in range(NUM_CLASSES):\n",
    "    classes = np.append(classes,np.array((np.where(y == i)),dtype=np.int32).reshape(-1,)[:minimum])\n",
    "\n",
    "X = X[classes] # extract our subset from entire dataset\n",
    "y = y[classes] #              \"\n",
    "\n",
    "X = X[:, 1:]  # remove the title column from the dataset since these are unique to each entry anyway\n",
    "\n",
    "splits = strat_k_fold.split(X, y)\n",
    "#scores = np.array([], dtype=np.float32).reshape(-1,)\n",
    "for train_index, test_index in splits:\n",
    "    # print('Train Index: {}'.format(train_index))\n",
    "    # print('Test Index: {}'.format(test_index))\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # TODO: use a grid search to determine the best learning constant\n",
    "    #       tweek C and max iterations to get good convergence and speed mix\n",
    "    log_reg_m = LogisticRegression(solver='lbfgs', C=0.1, max_iter=50000, multi_class='multinomial') #max_iter=50000\n",
    "    lin_reg_m = LinearRegression()\n",
    "    dtr_m = DecisionTreeRegressor()\n",
    "    rfr_m = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "    log_reg_m.fit(X_train, y_train)\n",
    "    lin_reg_m.fit(X_train, y_train)\n",
    "    dtr_m.fit(X_train, y_train)\n",
    "    rfr_m.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # print(log_reg_m.score(X_train,y_train))  # validating on test data\n",
    "\n",
    "    y1 = log_reg_m.predict(X_test) # this one works well not to sure about the others\n",
    "    y2 = lin_reg_m.predict(X_test)\n",
    "    y3 = dtr_m.predict(X_test)\n",
    "    y4 = rfr_m.predict(X_test)\n",
    "\n",
    "    # try taking an average and choosing the closest\n",
    "    prediction = (y1 + y2 + y3 + y4) / 4\n",
    "    prediction = np.around(prediction)\n",
    "    c1 = confidenceInterval()\n",
    "    c1.establish(prediction, y_test, 80) # want to know with 80% confidence\n",
    "    c1.printConfidence()\n",
    "\n",
    "    # TODO: try voting based on majority\n",
    "    # prediction = np.column_stack((y1,y2,y3,y4))\n",
    "\n",
    "#print(scores.sum()/strat_k_fold.n_splits)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
